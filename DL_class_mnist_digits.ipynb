{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL-class-mnist-digits.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPTpP5AtAGLs/z53qMxxmdT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarHash/Deep-Learning-Tutorials/blob/main/DL_class_mnist_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDSvsyMUcvD8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.mnist # 28x28 images of hand-written digits 0-9\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# let's see the tensor of one instance of the data\n",
        "print(x_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we will normalize (scale) the data\n",
        "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
        "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
        "\n",
        "print(x_train[0])"
      ],
      "metadata": {
        "id": "4r7b-ga-g0mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if we plot the data, it will be the number\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(x_test[0], cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "rQ3NUL1Sf4ue",
        "outputId": "032d1d1a-2941-4840-803a-de3406ff9638"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's create a model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# first is our input layer, we will flatten the dataset (remember our input is 28x28) using a layer called flatten as an input\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# now we add our dense layers with an activation function, and n neurons\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "\n",
        "# now we add our output layer. 10 neurons for 10 classes (0-9). We use softmax becuase this is a probability distribution\n",
        "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
        "\n",
        "\n",
        "# next is training the model\n",
        "model.compile(optimizer='adam', # the optimizer is usually dependent on an algorithm\n",
        "              loss='sparse_categorical_crossentropy', # loss is what the network calculates to learn, it will attempt to reduce it as it is learning\n",
        "              metrics=['accuracy']) # the scoring metric to track\n",
        "\n",
        "model.fit(x_train, y_train, epochs=8) # epochs is the number of passes through our whole dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8bGcDW9iKHl",
        "outputId": "695d690c-259e-4a16-e1f3-521c5332e709"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2690 - accuracy: 0.9200\n",
            "Epoch 2/8\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1064 - accuracy: 0.9666\n",
            "Epoch 3/8\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0719 - accuracy: 0.9775\n",
            "Epoch 4/8\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0542 - accuracy: 0.9827\n",
            "Epoch 5/8\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0411 - accuracy: 0.9868\n",
            "Epoch 6/8\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0308 - accuracy: 0.9895\n",
            "Epoch 7/8\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0247 - accuracy: 0.9915\n",
            "Epoch 8/8\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0209 - accuracy: 0.9927\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f042815f890>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we got good accuracy reults, now we check that our model is not overfitting on the test set\n",
        "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
        "print(val_loss, val_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xvp8BcOdnd0i",
        "outputId": "93117586-ba4c-42ec-a831-6c01bcbb713a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1083 - accuracy: 0.9744\n",
            "0.1082950308918953 0.974399983882904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's save our model\n",
        "model.save('my-digit-classifier.model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8cbBoSloVLq",
        "outputId": "f624c561-8178-4c47-feb6-0d71b43da687"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: my-digit-classifier.model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's use the saved model\n",
        "myModel = tf.keras.models.load_model('my-digit-classifier.model')"
      ],
      "metadata": {
        "id": "9Qw0Fhg1otQV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can also make predictions\n",
        "preds = myModel.predict([x_test])\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBzDt9Gco98j",
        "outputId": "2de4fcc9-f94c-4373-8a45-974b8ac8e72e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.92191466e-13, 2.53919080e-10, 3.83493948e-09, ...,\n",
              "        1.00000000e+00, 6.48004653e-13, 3.88375554e-10],\n",
              "       [3.43166399e-16, 1.72127136e-06, 9.99998331e-01, ...,\n",
              "        3.75237688e-12, 3.18901637e-14, 5.99597377e-19],\n",
              "       [9.51150530e-12, 1.00000000e+00, 1.45341206e-09, ...,\n",
              "        4.08148750e-08, 1.54596123e-08, 1.49856696e-10],\n",
              "       ...,\n",
              "       [1.55011349e-14, 7.49392370e-09, 5.31108421e-11, ...,\n",
              "        1.64477342e-07, 1.89427904e-10, 2.27815899e-08],\n",
              "       [5.09660639e-14, 1.20484795e-08, 1.33521149e-14, ...,\n",
              "        2.83922774e-10, 2.66049831e-08, 6.07343323e-16],\n",
              "       [2.27566854e-10, 9.63003635e-11, 8.03599288e-12, ...,\n",
              "        1.39687824e-15, 4.73497803e-12, 2.26733123e-15]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# note that our predictions are tensors, probably one-hot encoded\n",
        "# we will use argmax to return the value of the class with the highest possibility\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(np.argmax(preds[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OUxVdFLpXuk",
        "outputId": "c282a287-e3b9-4517-b4ee-4d89375cf148"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    }
  ]
}